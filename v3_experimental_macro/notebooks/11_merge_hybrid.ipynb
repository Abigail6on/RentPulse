{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd7234bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öõÔ∏è  Initializing Fusion Reactor...\n",
      "   üîß Checking Data Integrity...\n",
      "      ‚úÖ Found Housing\n",
      "      ‚úÖ Found Rates\n",
      "      ‚úÖ Found Unemp\n",
      "      ‚úÖ Found GDP\n",
      "      ‚úÖ Found Pop\n",
      "   üîÑ Loading Datasets...\n",
      "   üó∫Ô∏è  Mapping Geography...\n",
      "   üîó Merging Interest Rates...\n",
      "   üîó Merging GDP...\n",
      "   üîó Merging Unemployment...\n",
      "   üîó Merging Population...\n",
      "   ‚ú® Final Polish...\n",
      "      Dropping helper columns: ['City_Map_x', 'City_Map_y']\n",
      "----------------------------------------\n",
      "‚úÖ FUSION COMPLETE: ../data/processed/hybrid_v3_dataset.csv\n",
      "   Total Rows: 2189\n",
      "   Columns: ['City', 'Turnover_Rate', 'Average rent ($)', 'Year', 'Total_Units', 'Buy_Price', 'Intl_Students_Prov', 'Province', 'Region_Map', 'Interest_Rate', 'GDP_Growth_Pct', 'Unemployment_Rate', 'Pop_Growth_Pct']\n",
      "----------------------------------------\n",
      "Sample Data Check:\n",
      "                  City  Year  GDP_Growth_Pct  Pop_Growth_Pct\n",
      "0  Abbotsford-Mission  2015        0.000000             0.0\n",
      "1  Abbotsford-Mission  2016        2.948916             0.0\n",
      "2  Abbotsford-Mission  2017        3.658435             0.0\n",
      "3  Abbotsford-Mission  2018        3.799127             0.0\n",
      "4  Abbotsford-Mission  2019        2.866204             0.0\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# V3 STEP 2: THE FUSION REACTOR (Fixed & Polished) ‚öõÔ∏è\n",
    "# =========================================================\n",
    "# Goal: Merge Housing Data with Interest Rates, GDP, Unemployment, and Population.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. SETUP PATHS\n",
    "BASE_DIR = \"..\" \n",
    "RAW_HOUSING_PATH = os.path.join(BASE_DIR, \"data/raw_housing\")\n",
    "PROCESSED_PATH = os.path.join(BASE_DIR, \"data/processed\")\n",
    "\n",
    "# Define File Map\n",
    "FILES = {\n",
    "    \"Housing\": os.path.join(RAW_HOUSING_PATH, \"national_master_dataset.csv\"),\n",
    "    \"Rates\": os.path.join(PROCESSED_PATH, \"clean_interest_rates.csv\"),\n",
    "    \"Unemp\": os.path.join(PROCESSED_PATH, \"clean_unemployment.csv\"),\n",
    "    \"GDP\": os.path.join(PROCESSED_PATH, \"clean_gdp.csv\"),\n",
    "    \"Pop\": os.path.join(PROCESSED_PATH, \"clean_population.csv\")\n",
    "}\n",
    "\n",
    "print(\"‚öõÔ∏è  Initializing Fusion Reactor...\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MODULE 1: AUTO-REPAIR\n",
    "# ---------------------------------------------------------\n",
    "def repair_macro_data():\n",
    "    print(\"   üîß Checking Data Integrity...\")\n",
    "    for key, fpath in FILES.items():\n",
    "        if not os.path.exists(fpath):\n",
    "             raise FileNotFoundError(f\"üö® CRITICAL: {key} file missing at: {fpath}\")\n",
    "        print(f\"      ‚úÖ Found {key}\")\n",
    "\n",
    "repair_macro_data()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MODULE 2: GEOGRAPHY MAPPING (Mega-Dictionary) üó∫Ô∏è\n",
    "# ---------------------------------------------------------\n",
    "# Maps City -> (Province, Economic Region)\n",
    "# Note: Territories are mapped to provinces as GDP proxies if local data missing\n",
    "GEO_MAP = {\n",
    "    # TERRITORIES (Proxies for GDP)\n",
    "    'Yellowknife': ('Alberta', 'Yellowknife'), # Proxy Alberta\n",
    "    'Whitehorse': ('British Columbia', 'Whitehorse'), # Proxy BC\n",
    "    'Iqaluit': ('Quebec', 'Iqaluit'), # Proxy Quebec\n",
    "    \n",
    "    # ONTARIO\n",
    "    'Toronto': ('Ontario', 'Toronto'), 'Ottawa': ('Ontario', 'Ottawa'), 'Hamilton': ('Ontario', 'Hamilton-Niagara Peninsula'),\n",
    "    'Kitchener': ('Ontario', 'Kitchener-Waterloo-Barrie'), 'London': ('Ontario', 'London'), 'Windsor': ('Ontario', 'Windsor-Sarnia'),\n",
    "    'Oshawa': ('Ontario', 'Toronto'), 'Barrie': ('Ontario', 'Kitchener-Waterloo-Barrie'), 'Kingston': ('Ontario', 'Kingston-Pembroke'),\n",
    "    'Guelph': ('Ontario', 'Kitchener-Waterloo-Barrie'), 'Sudbury': ('Ontario', 'Northeast'), 'Thunder Bay': ('Ontario', 'Northwest'),\n",
    "    'Peterborough': ('Ontario', 'Muskoka-Kawarthas'), 'Brantford': ('Ontario', 'Hamilton-Niagara Peninsula'),\n",
    "    'Belleville': ('Ontario', 'Kingston-Pembroke'), 'Sarnia': ('Ontario', 'Windsor-Sarnia'), 'Sault Ste. Marie': ('Ontario', 'Northeast'),\n",
    "    'St. Catharines-Niagara': ('Ontario', 'Hamilton-Niagara Peninsula'), 'St. Catharines': ('Ontario', 'Hamilton-Niagara Peninsula'),\n",
    "    'Niagara Falls': ('Ontario', 'Hamilton-Niagara Peninsula'), 'Cambridge': ('Ontario', 'Kitchener-Waterloo-Barrie'),\n",
    "    'Waterloo': ('Ontario', 'Kitchener-Waterloo-Barrie'), 'Mississauga': ('Ontario', 'Toronto'), 'Brampton': ('Ontario', 'Toronto'),\n",
    "    'Markham': ('Ontario', 'Toronto'), 'Vaughan': ('Ontario', 'Toronto'), 'Richmond Hill': ('Ontario', 'Toronto'),\n",
    "    'Oakville': ('Ontario', 'Toronto'), 'Burlington': ('Ontario', 'Hamilton-Niagara Peninsula'),\n",
    "    # BC\n",
    "    'Vancouver': ('British Columbia', 'Lower Mainland-Southwest'), 'Victoria': ('British Columbia', 'Vancouver Island and Coast'),\n",
    "    'Kelowna': ('British Columbia', 'Thompson-Okanagan'), 'Abbotsford-Mission': ('British Columbia', 'Lower Mainland-Southwest'),\n",
    "    'Abbotsford': ('British Columbia', 'Lower Mainland-Southwest'), 'Nanaimo': ('British Columbia', 'Vancouver Island and Coast'),\n",
    "    'Kamloops': ('British Columbia', 'Thompson-Okanagan'), 'Chilliwack': ('British Columbia', 'Lower Mainland-Southwest'),\n",
    "    'Prince George': ('British Columbia', 'Cariboo'), 'Surrey': ('British Columbia', 'Lower Mainland-Southwest'),\n",
    "    'Burnaby': ('British Columbia', 'Lower Mainland-Southwest'), 'Richmond': ('British Columbia', 'Lower Mainland-Southwest'),\n",
    "    # ALBERTA\n",
    "    'Calgary': ('Alberta', 'Calgary'), 'Edmonton': ('Alberta', 'Edmonton'), 'Red Deer': ('Alberta', 'Red Deer'),\n",
    "    'Lethbridge': ('Alberta', 'Lethbridge-Medicine Hat'), 'Medicine Hat': ('Alberta', 'Lethbridge-Medicine Hat'),\n",
    "    'Wood Buffalo': ('Alberta', 'Wood Buffalo-Cold Lake'), 'Grande Prairie': ('Alberta', 'Banff-Jasper-Rocky Mountain House and Athabasca-Grande Prairie-Peace River'),\n",
    "    # QUEBEC\n",
    "    'Montreal': ('Quebec', 'Montreal'), 'Quebec': ('Quebec', 'Capitale-Nationale'), 'Gatineau': ('Quebec', 'Outaouais'),\n",
    "    'Sherbrooke': ('Quebec', 'Estrie'), 'Trois-Rivieres': ('Quebec', 'Mauricie'), 'Saguenay': ('Quebec', 'Saguenay-Lac-Saint-Jean'),\n",
    "    'Drummondville': ('Quebec', 'Mauricie'), 'Laval': ('Quebec', 'Laval'), 'Longueuil': ('Quebec', 'Mont√©r√©gie'),\n",
    "    # PRAIRIES & ATLANTIC\n",
    "    'Winnipeg': ('Manitoba', 'Winnipeg'), 'Saskatoon': ('Saskatchewan', 'Saskatoon-Biggar'),\n",
    "    'Regina': ('Saskatchewan', 'Regina-Moose Mountain'), 'Halifax': ('Nova Scotia', 'Halifax'),\n",
    "    'Moncton': ('New Brunswick', 'Moncton-Richibucto'), 'Saint John': ('New Brunswick', 'Saint John-St. Stephen'),\n",
    "    'St. Johns': ('Newfoundland and Labrador', 'Avalon Peninsula'), 'Charlottetown': ('Prince Edward Island', 'Prince Edward Island')\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MODULE 3: THE MERGE ENGINE üöÇ\n",
    "# ---------------------------------------------------------\n",
    "print(\"   üîÑ Loading Datasets...\")\n",
    "try:\n",
    "    df_housing = pd.read_csv(FILES[\"Housing\"])\n",
    "    df_rates = pd.read_csv(FILES[\"Rates\"])\n",
    "    df_unemp = pd.read_csv(FILES[\"Unemp\"])\n",
    "    df_gdp = pd.read_csv(FILES[\"GDP\"])\n",
    "    df_pop = pd.read_csv(FILES[\"Pop\"])\n",
    "    \n",
    "    # 1. Apply Geography Map\n",
    "    print(\"   üó∫Ô∏è  Mapping Geography...\")\n",
    "    df_housing['City'] = df_housing['City'].str.strip()\n",
    "    \n",
    "    # Map Province and Region (Handle missing keys safely)\n",
    "    df_housing['Province'] = df_housing['City'].apply(lambda c: GEO_MAP.get(c, (\"Unknown\", \"Unknown\"))[0])\n",
    "    df_housing['Region_Map'] = df_housing['City'].apply(lambda c: GEO_MAP.get(c, (c, c))[1]) # Fallback to City Name\n",
    "    \n",
    "    # 2. Merge Interest Rates (on Year)\n",
    "    print(\"   üîó Merging Interest Rates...\")\n",
    "    df_merged = pd.merge(df_housing, df_rates[['Year', 'Interest_Rate']], on='Year', how='left')\n",
    "    \n",
    "    # 3. Merge GDP (on Province + Year)\n",
    "    print(\"   üîó Merging GDP...\")\n",
    "    df_merged = pd.merge(df_merged, df_gdp[['Province', 'Year', 'GDP_Growth_Pct']], on=['Province', 'Year'], how='left')\n",
    "    \n",
    "    # 4. Merge Unemployment (on Region + Year)\n",
    "    print(\"   üîó Merging Unemployment...\")\n",
    "    df_merged = pd.merge(df_merged, df_unemp[['City_Map', 'Year', 'Unemployment_Rate']], \n",
    "                         left_on=['Region_Map', 'Year'], right_on=['City_Map', 'Year'], how='left')\n",
    "    \n",
    "    # 5. Merge Population (on City + Year)\n",
    "    print(\"   üîó Merging Population...\")\n",
    "    # Using left_on='City' assumes Population file has clean names matching Housing file\n",
    "    df_merged = pd.merge(df_merged, df_pop[['City_Map', 'Year', 'Pop_Growth_Pct']], \n",
    "                         left_on=['City', 'Year'], right_on=['City_Map', 'Year'], how='left')\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # MODULE 4: FINAL POLISH (Fixing the Error) ‚ú®\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"   ‚ú® Final Polish...\")\n",
    "    \n",
    "    # FIX: Use direct assignment instead of inplace=True to avoid ChainedAssignmentError\n",
    "    \n",
    "    # Unemployment: Fill missing with National Mean for that year\n",
    "    means_unemp = df_merged.groupby('Year')['Unemployment_Rate'].transform('mean')\n",
    "    df_merged['Unemployment_Rate'] = df_merged['Unemployment_Rate'].fillna(means_unemp)\n",
    "    \n",
    "    # GDP: Fill missing with 0.0\n",
    "    df_merged['GDP_Growth_Pct'] = df_merged['GDP_Growth_Pct'].fillna(0.0)\n",
    "    \n",
    "    # Population: Fill missing with 0.0\n",
    "    df_merged['Pop_Growth_Pct'] = df_merged['Pop_Growth_Pct'].fillna(0.0)\n",
    "    \n",
    "    # Drop Cleanup (Remove duplicate/helper columns)\n",
    "    cols_to_drop = [c for c in df_merged.columns if 'City_Map' in c]\n",
    "    if cols_to_drop:\n",
    "        print(f\"      Dropping helper columns: {cols_to_drop}\")\n",
    "        df_merged = df_merged.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Save\n",
    "    out_file = os.path.join(PROCESSED_PATH, \"hybrid_v3_dataset.csv\")\n",
    "    df_merged.to_csv(out_file, index=False)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"‚úÖ FUSION COMPLETE: {out_file}\")\n",
    "    print(f\"   Total Rows: {len(df_merged)}\")\n",
    "    print(f\"   Columns: {df_merged.columns.tolist()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Diagnostic Check\n",
    "    sample_check = df_merged[['City', 'Year', 'GDP_Growth_Pct', 'Pop_Growth_Pct']].head()\n",
    "    print(\"Sample Data Check:\\n\", sample_check)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå FUSION ERROR: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
