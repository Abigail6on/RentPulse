{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3acb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Macro Refinery...\n",
      "\n",
      "[1/4] Processing Interest Rates...\n",
      "   üìç Found header at line 11 in boc_interest_rates.csv\n",
      "   ‚úÖ Saved Interest Rates: 12 years\n",
      "\n",
      "[2/4] Processing Unemployment...\n",
      "   üìç Found header at line 10 in unemployment_stats.csv\n",
      "   ‚úÖ Saved Unemployment: 836 rows\n",
      "\n",
      "[3/4] Processing GDP...\n",
      "   üìç Found header at line 10 in provincial_gdp.csv\n",
      "   ‚úÖ Saved GDP: 100 rows\n",
      "\n",
      "[4/4] Processing Population...\n",
      "   üìç Found header at line 10 in Population.csv\n",
      "   ‚úÖ Saved Population: 2321 rows\n",
      "\n",
      "‚ú® REFINERY COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# V3 STEP 1: MACRO DATA REFINERY (Footer-Proof Edition) üè≠\n",
    "# =========================================================\n",
    "# Goal: Standardize 4 disparate data sources into Annual Time Series.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. SETUP PATHS\n",
    "BASE_DIR = \"..\" \n",
    "RAW_PATH = os.path.join(BASE_DIR, \"data/raw_macro\")\n",
    "PROCESSED_PATH = os.path.join(BASE_DIR, \"data/processed\")\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"üöÄ Starting Macro Refinery...\")\n",
    "\n",
    "# --- Helper: Robust Loader ---\n",
    "def robust_load(filepath, keywords, skip_summary=False):\n",
    "    \"\"\"\n",
    "    Finds the header row index by scanning lines, then loads CSV \n",
    "    with skip_blank_lines=False to ensure index alignment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Find Header Row Index (0-based)\n",
    "        header_row = -1\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for i, line in enumerate(lines):\n",
    "            # Special check for BoC summary block\n",
    "            if skip_summary and \"Summary\" in line: continue\n",
    "            \n",
    "            # Check if all keywords are in the line\n",
    "            if all(k in line for k in keywords):\n",
    "                header_row = i\n",
    "                print(f\"   üìç Found header at line {i} in {os.path.basename(filepath)}\")\n",
    "                break\n",
    "        \n",
    "        if header_row == -1:\n",
    "            print(f\"   ‚ùå Header not found in {os.path.basename(filepath)}\")\n",
    "            return None\n",
    "\n",
    "        # 2. Load Data (skip_blank_lines=False is crucial here!)\n",
    "        df = pd.read_csv(filepath, header=header_row, skip_blank_lines=False)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error loading {os.path.basename(filepath)}: {e}\")\n",
    "        return None\n",
    "\n",
    "# =========================================================\n",
    "# MODULE A: INTEREST RATES (Gravity) üìâ\n",
    "# =========================================================\n",
    "print(\"\\n[1/4] Processing Interest Rates...\")\n",
    "df_rates = robust_load(f\"{RAW_PATH}/boc_interest_rates.csv\", [\"Date\", \"V39079\"], skip_summary=True)\n",
    "\n",
    "if df_rates is not None:\n",
    "    try:\n",
    "        df_rates = df_rates.iloc[:, 0:2] # Keep Date and Rate\n",
    "        df_rates.columns = ['Date', 'Interest_Rate']\n",
    "        \n",
    "        df_rates['Date'] = pd.to_datetime(df_rates['Date'], errors='coerce')\n",
    "        df_rates.dropna(subset=['Date'], inplace=True)\n",
    "        df_rates['Interest_Rate'] = pd.to_numeric(df_rates['Interest_Rate'], errors='coerce')\n",
    "        \n",
    "        # Annualize\n",
    "        df_rates['Year'] = df_rates['Date'].dt.year\n",
    "        df_rates_annual = df_rates.groupby('Year')['Interest_Rate'].mean().reset_index()\n",
    "\n",
    "        # Patch 2014-2015\n",
    "        if 2015 not in df_rates_annual['Year'].values:\n",
    "            history = pd.DataFrame([{'Year': 2014, 'Interest_Rate': 1.00}, {'Year': 2015, 'Interest_Rate': 0.63}])\n",
    "            df_rates_annual = pd.concat([history, df_rates_annual], ignore_index=True)\n",
    "\n",
    "        df_rates_annual.sort_values('Year').to_csv(f\"{PROCESSED_PATH}/clean_interest_rates.csv\", index=False)\n",
    "        print(f\"   ‚úÖ Saved Interest Rates: {len(df_rates_annual)} years\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error cleaning Interest Rates: {e}\")\n",
    "\n",
    "# =========================================================\n",
    "# MODULE B: UNEMPLOYMENT (Ability to Pay) üíº\n",
    "# =========================================================\n",
    "print(\"\\n[2/4] Processing Unemployment...\")\n",
    "df_unemp = robust_load(f\"{RAW_PATH}/unemployment_stats.csv\", [\"Geography\", \"January\"])\n",
    "\n",
    "if df_unemp is not None:\n",
    "    try:\n",
    "        df_unemp.rename(columns={df_unemp.columns[0]: 'Region'}, inplace=True)\n",
    "\n",
    "        # Drop Unit Row\n",
    "        if len(df_unemp) > 0 and \"Percent\" in str(df_unemp.iloc[0, 1]):\n",
    "            df_unemp = df_unemp.iloc[1:].copy()\n",
    "\n",
    "        # Melt\n",
    "        df_long = df_unemp.melt(id_vars=['Region'], var_name='Date_Str', value_name='Unemployment_Rate')\n",
    "        \n",
    "        # Extract Year\n",
    "        df_long['Year'] = df_long['Date_Str'].astype(str).str.extract(r'(\\d{4})')\n",
    "        df_long['Unemployment_Rate'] = pd.to_numeric(df_long['Unemployment_Rate'], errors='coerce')\n",
    "        \n",
    "        df_long.dropna(subset=['Year', 'Unemployment_Rate'], inplace=True)\n",
    "        df_long['Year'] = df_long['Year'].astype(int)\n",
    "        \n",
    "        # Annual Average\n",
    "        df_unemp_annual = df_long.groupby(['Region', 'Year'])['Unemployment_Rate'].mean().reset_index()\n",
    "        \n",
    "        # Clean Region Names\n",
    "        df_unemp_annual['City_Map'] = df_unemp_annual['Region'].apply(lambda x: str(x).split(',')[0].strip())\n",
    "        \n",
    "        df_unemp_annual.to_csv(f\"{PROCESSED_PATH}/clean_unemployment.csv\", index=False)\n",
    "        print(f\"   ‚úÖ Saved Unemployment: {len(df_unemp_annual)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error cleaning Unemployment: {e}\")\n",
    "\n",
    "# =========================================================\n",
    "# MODULE C: PROVINCIAL GDP (Optimism) üìà\n",
    "# =========================================================\n",
    "print(\"\\n[3/4] Processing GDP...\")\n",
    "df_gdp = robust_load(f\"{RAW_PATH}/provincial_gdp.csv\", [\"Geography\", \"2015\"])\n",
    "\n",
    "if df_gdp is not None:\n",
    "    try:\n",
    "        df_gdp.rename(columns={df_gdp.columns[0]: 'Province'}, inplace=True)\n",
    "        \n",
    "        # Drop Unit Row\n",
    "        if len(df_gdp) > 0 and \"Dollars\" in str(df_gdp.iloc[0, 1]):\n",
    "            df_gdp = df_gdp.iloc[1:].copy()\n",
    "        \n",
    "        valid_provinces = ['Ontario', 'British Columbia', 'Quebec', 'Alberta', 'Nova Scotia', \n",
    "                           'Manitoba', 'Saskatchewan', 'New Brunswick', 'Newfoundland and Labrador', 'Prince Edward Island']\n",
    "        df_gdp = df_gdp[df_gdp['Province'].isin(valid_provinces)].copy()\n",
    "        \n",
    "        # Melt\n",
    "        year_cols = [c for c in df_gdp.columns if c.strip().isdigit()]\n",
    "        df_gdp_long = df_gdp.melt(id_vars=['Province'], value_vars=year_cols, var_name='Year', value_name='GDP_Millions')\n",
    "        \n",
    "        # Clean Numeric (Handle Commas & Footnotes)\n",
    "        df_gdp_long['GDP_Millions'] = pd.to_numeric(\n",
    "            df_gdp_long['GDP_Millions'].astype(str).str.replace(',', ''), \n",
    "            errors='coerce'\n",
    "        )\n",
    "        df_gdp_long.dropna(subset=['GDP_Millions'], inplace=True)\n",
    "        df_gdp_long['Year'] = df_gdp_long['Year'].astype(int)\n",
    "        \n",
    "        # Calculate Growth %\n",
    "        df_gdp_long.sort_values(['Province', 'Year'], inplace=True)\n",
    "        df_gdp_long['GDP_Growth_Pct'] = df_gdp_long.groupby('Province')['GDP_Millions'].pct_change() * 100\n",
    "        \n",
    "        df_gdp_long.to_csv(f\"{PROCESSED_PATH}/clean_gdp.csv\", index=False)\n",
    "        print(f\"   ‚úÖ Saved GDP: {len(df_gdp_long)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error cleaning GDP: {e}\")\n",
    "\n",
    "# =========================================================\n",
    "# MODULE D: POPULATION (Demand) üë®‚Äçüë©‚Äçüëß‚Äçüë¶\n",
    "# =========================================================\n",
    "print(\"\\n[4/4] Processing Population...\")\n",
    "df_pop = robust_load(f\"{RAW_PATH}/Population.csv\", [\"Geography\", \"2015\"])\n",
    "\n",
    "if df_pop is not None:\n",
    "    try:\n",
    "        df_pop.rename(columns={df_pop.columns[0]: 'Region'}, inplace=True)\n",
    "        \n",
    "        # Drop Unit Row\n",
    "        if len(df_pop) > 0 and \"Persons\" in str(df_pop.iloc[0, 1]):\n",
    "            df_pop = df_pop.iloc[1:].copy()\n",
    "            \n",
    "        # Melt\n",
    "        year_cols = [c for c in df_pop.columns if c.strip().isdigit()]\n",
    "        df_pop_long = df_pop.melt(id_vars=['Region'], value_vars=year_cols, var_name='Year', value_name='Population')\n",
    "        \n",
    "        # Clean Numeric (THE FIX: Force errors='coerce' to drop footnotes)\n",
    "        df_pop_long['Population'] = pd.to_numeric(\n",
    "            df_pop_long['Population'].astype(str).str.replace(',', ''), \n",
    "            errors='coerce'\n",
    "        )\n",
    "        # Drop rows that became NaN (the footer text rows)\n",
    "        df_pop_long.dropna(subset=['Population'], inplace=True)\n",
    "        \n",
    "        df_pop_long['Year'] = df_pop_long['Year'].astype(int)\n",
    "        \n",
    "        # Calculate Growth %\n",
    "        df_pop_long.sort_values(['Region', 'Year'], inplace=True)\n",
    "        df_pop_long['Pop_Growth_Pct'] = df_pop_long.groupby('Region')['Population'].pct_change() * 100\n",
    "        \n",
    "        # Clean City Names\n",
    "        def clean_pop_city(val):\n",
    "            val = str(val).split(',')[0].strip()\n",
    "            for s in ['(CMA)', '(CA)', ' part', 'metro']:\n",
    "                val = val.replace(s, '')\n",
    "            return val.strip()\n",
    "\n",
    "        df_pop_long['City_Map'] = df_pop_long['Region'].apply(clean_pop_city)\n",
    "        \n",
    "        df_pop_long.to_csv(f\"{PROCESSED_PATH}/clean_population.csv\", index=False)\n",
    "        print(f\"   ‚úÖ Saved Population: {len(df_pop_long)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error cleaning Population: {e}\")\n",
    "\n",
    "print(\"\\n‚ú® REFINERY COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
